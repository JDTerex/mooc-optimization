{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm tests the current trial step. If if is too long (that is, if Wolfe 1 is violated), the step is shortened. If it is too long (that is, if Wolfe 2 is violated), the step is increased. A lower and an upper bound are maintained at each iteration to control the processus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineSearch(obj, x, d, alpha0, beta1, beta2, lbd):\n",
    "    \"\"\"\n",
    "    :param obj: function returning the value of the objective function and its gradient.\n",
    "    :type obj: f, g = fct(x)\n",
    "    \n",
    "    :param x: point where the line search starts.\n",
    "    :type x: numpy array\n",
    "    \n",
    "    :param d: direction along which the line search is performed.\n",
    "    :type d: numpy array (size dimension as x)\n",
    "    \n",
    "    :param alpha0: first trial for the step\n",
    "    :type alpha0: float. Must be positive. \n",
    "    \n",
    "    :param beta1: parameter for the first Wolfe condition. \n",
    "    :type beta1: float. Must be strictly between 0 and 1.\n",
    "    \n",
    "    :param beta2: parameter for the second Wolfe condition. \n",
    "    :type beta2: float. Must be strictly between 0 and 1, and beta2 > beta1.\n",
    "    \n",
    "    \"\"\"\n",
    "    if  lbd <= 1:\n",
    "        raise Exception(f'lambda is {lbd} and must be > 1')\n",
    "    if  alpha0 <= 0:\n",
    "        raise Exception(f'alpha0 is {alpha0} and must be > 0')\n",
    "    if beta1 <= 0 or beta1 >= 1:\n",
    "         raise Exception(f'beta1 = {beta1} must be strictly between 0 and 1')\n",
    "    if beta2 >= 1:\n",
    "         raise Exception(f'beta2 = {beta2} must be strictly lesser than 1')       \n",
    "    if  beta1 >= beta2:\n",
    "        raise Exception(f'Incompatible Wolfe cond. parameters: beta1={beta1} is greater or equal than beta2={beta2}')\n",
    "        \n",
    "    f, g = obj(x)\n",
    "    deriv = np.inner(g,d)\n",
    "    if deriv >= 0:\n",
    "        raise Exception(f'd is not a descent direction: {deriv} >= 0')\n",
    "    i = 0\n",
    "    alpha = alpha0\n",
    "    # The lower bound alphal is initialized to 0.\n",
    "    alphal = 0\n",
    "    # The upper bound alphar is initialized to \"infinity\", that is, the largest floating point number\n",
    "    # representable in the machine. \n",
    "    alphar = np.finfo(np.float64).max\n",
    "    finished = False\n",
    "    iters = list()\n",
    "    while not finished:\n",
    "        xnew = x + alpha * d\n",
    "        fnew, gnew = obj(xnew)\n",
    "        # First Wolfe condition\n",
    "        if fnew > f + alpha * beta1 * deriv:\n",
    "            reason = \"too long\"\n",
    "            alphar = alpha ;\n",
    "            alpha = (alphal + alphar) / 2.0\n",
    "        # Second Wolfe condition\n",
    "        elif np.inner(gnew, d) < beta2 * deriv:\n",
    "            reason = \"too short\"\n",
    "            alphal = alpha \n",
    "            if alphar == np.finfo(np.float64).max:\n",
    "                alpha = lbd * alpha \n",
    "            else:\n",
    "                alpha = (alphal + alphar) / 2.0\n",
    "        else:\n",
    "            reason = \"ok\"\n",
    "            finished = True\n",
    "        iters.append([alpha, alphal, alphar, reason])\n",
    "    return alpha, iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function \\\\[ f(x) = \\frac{1}{2} x_1^2 + \\frac{9}{2} x_2^2  \\\\]\n",
    "for which the gradient is \\\\[ \\nabla f(x) = \\left( \\begin{array}{c} x_1 \\\\ 9x_2 \\end{array} \\right).\\\\]\n",
    "Consider the vector $x= \\left( \\begin{array}{c} 10 \\\\ 1 \\end{array} \\right)$ and the descent direction $d= \\left( \\begin{array}{c} -2/\\sqrt{5} \\\\ 1/\\sqrt{5} \\end{array} \\right).$\n",
    "\n",
    "Define $\\alpha_0=10^{-3}$, $\\beta_1=0.3$, $\\beta_2=0.7$ and $\\lambda=20$.\n",
    "\n",
    "We apply the line search algorithm in order to find a step $\\alpha^*$ such that the Wolfe conditions are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, in Python, the numbering of arrays start at 0.\n",
    "def func_grad(x):\n",
    "    f = 0.5 * x[0] * x[0] + 4.5 * x[1] * x[1]\n",
    "    g = np.array([x[0], 9 * x[1]])\n",
    "    H = np.array([[1, 0], [0, 9]])\n",
    "    return f, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is 2.3000000000000003 and the number of iterations of the algorithm is 5\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10, 1])\n",
    "d = np.array([-2 / np.sqrt(5), 1 / np.sqrt(5)])\n",
    "alpha0 = 1.0e-3\n",
    "beta1 = 0.3\n",
    "beta2 = 0.7\n",
    "lbd = 20\n",
    "alpha, iters = lineSearch(func_grad, x, d, alpha0, beta1, beta2, lbd)\n",
    "print(f'The step is {alpha} and the number of iterations of the algorithm is {len(iters)-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\t\talpha_l\t\talpha_u\t\tReason\n",
      "+2.000000E-02\t+1.000000E-03\t+1.797693E+308\ttoo short\n",
      "+4.000000E-01\t+2.000000E-02\t+1.797693E+308\ttoo short\n",
      "+8.000000E+00\t+4.000000E-01\t+1.797693E+308\ttoo short\n",
      "+4.200000E+00\t+4.000000E-01\t+8.000000E+00\ttoo long\n",
      "+2.300000E+00\t+4.000000E-01\t+4.200000E+00\ttoo long\n",
      "+2.300000E+00\t+4.000000E-01\t+4.200000E+00\tok\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha\\t\\talpha_l\\t\\talpha_u\\t\\tReason\")\n",
    "for k in range(len(iters)):\n",
    "    print(\"{:+E}\\t{:+E}\\t{:+13E}\\t{:}\".format(*(iters[k])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the parameters used in this example have been chosen to illustrate all the cases and are not appropriate in practice. Thus we next use more appropriate ones with $\\alpha_0=1$, $\\beta_1=10^{-4}$, $\\beta_2=0.99$ and $\\lambda=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step is 1 and the number of iterations of the algorithm is 0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10, 1])\n",
    "d = np.array([-2 / np.sqrt(5), 1 / np.sqrt(5)])\n",
    "alpha0 = 1\n",
    "beta1bis = 1.0e-4\n",
    "beta2bis = 0.99\n",
    "lbdbis = 2\n",
    "alpha2, iters2 = lineSearch(func_grad, x, d,alpha0, beta1bis, beta2bis, lbdbis)\n",
    "print(f'The step is {alpha2} and the number of iterations of the algorithm is {len(iters2)-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\t\talpha_l\t\talpha_u\t\tReason\n",
      "+1.000000E+00\t+0.000000E+00\t+1.797693E+308\tok\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha\\t\\talpha_l\\t\\talpha_u\\t\\tReason\")\n",
    "for k in range(len(iters2)):\n",
    "    print(\"{:+E}\\t{:+E}\\t{:+13E}\\t{:}\".format(*(iters2[k])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
